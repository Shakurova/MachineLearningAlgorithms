{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть две идеи:\n",
    "### 1-ая идея:\n",
    "\n",
    "- Обучение:\n",
    "Вытащить из корпуса все positive / negative слова\n",
    "Векторизовать каждое слово с помощью word2vec\n",
    "Написать простой классификатор (вектор - класс)\n",
    "\n",
    "- Тестирование:\n",
    "На вход поступает слово\n",
    "Вектурезуем его с помощью word2vec и делаем predict\n",
    "\n",
    "\n",
    "### 2-ая идея\n",
    "\n",
    "- Обучение\n",
    "Подать на word2vec сначала негативные слова, векторизовать, записать в массив. \n",
    "Потом подать на word2vec позитивные, векторизовать. \n",
    "Получится два облака.\n",
    "\n",
    "- Тестирование\n",
    "Далее входные слова сравнивать с каждым из этих двух облаков.\n",
    "Берем входное слово, сравниваем его с каждым словом из позитивного облака, запиисываем расстояние. \n",
    "Потом сравниваем с каждым словом из негативного облака и тоже считаем расстояние. \n",
    "Сравниваем результаты по расстояниям по разным облакам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import division\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lxml import etree\n",
    "\n",
    "import pymorphy2\n",
    "import math\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "import gensim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn import cross_validation\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "RUS_LETTERS = u'абвгдеёжзийклмнопрстуфхцчшщъыьэюя'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_xml(filename):\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        xml = f.read()\n",
    "\n",
    "    dict = {}\n",
    "    text = []\n",
    "    category = []\n",
    "    sentiment = []\n",
    "    term = []\n",
    "\n",
    "    root = etree.fromstring(xml)\n",
    "    for child in root:\n",
    "        for aspect in child[3]:\n",
    "            if aspect.attrib['type'] == 'implicit' and aspect.attrib['sentiment']!= 'both' and aspect.attrib['sentiment']!= 'neutral':\n",
    "                text.append(child[2].text)\n",
    "                category.append(aspect.attrib['category'])\n",
    "                sentiment.append(aspect.attrib['sentiment'])\n",
    "                term.append(aspect.attrib['term'])\n",
    "\n",
    "    dict['text'] = text\n",
    "    dict['category'] = category\n",
    "    dict['sentiment'] = sentiment\n",
    "    dict['term'] = term\n",
    "\n",
    "    \n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_train = parse_xml('SentiRuEval_rest_markup_train.xml')\n",
    "text_test = parse_xml('SentiRuEval_rest_markup_test.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Создаем датафрейм из тестового и тренировочного корпуса\n",
    "\n",
    "df1 = pd.DataFrame(text_train)\n",
    "df2 = pd.DataFrame(text_test)\n",
    "\n",
    "frames = [df1, df2]\n",
    "df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>term</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Food</td>\n",
       "      <td>positive</td>\n",
       "      <td>вкусное</td>\n",
       "      <td>День 8-го марта прошёл, можно и итоги подвести...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Interior</td>\n",
       "      <td>positive</td>\n",
       "      <td>уютный</td>\n",
       "      <td>День 8-го марта прошёл, можно и итоги подвести...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Food</td>\n",
       "      <td>positive</td>\n",
       "      <td>вкусные</td>\n",
       "      <td>Отмечали в этом ресторане день рождение на пер...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Interior</td>\n",
       "      <td>positive</td>\n",
       "      <td>уютно</td>\n",
       "      <td>Отмечали в этом ресторане день рождение на пер...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Interior</td>\n",
       "      <td>positive</td>\n",
       "      <td>красиво</td>\n",
       "      <td>Отмечали в этом ресторане день рождение на пер...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category sentiment     term  \\\n",
       "0      Food  positive  вкусное   \n",
       "1  Interior  positive   уютный   \n",
       "2      Food  positive  вкусные   \n",
       "3  Interior  positive    уютно   \n",
       "4  Interior  positive  красиво   \n",
       "\n",
       "                                                text  \n",
       "0  День 8-го марта прошёл, можно и итоги подвести...  \n",
       "1  День 8-го марта прошёл, можно и итоги подвести...  \n",
       "2  Отмечали в этом ресторане день рождение на пер...  \n",
       "3  Отмечали в этом ресторане день рождение на пер...  \n",
       "4  Отмечали в этом ресторане день рождение на пер...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>term</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1367</td>\n",
       "      <td>1367</td>\n",
       "      <td>1367</td>\n",
       "      <td>1367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>505</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Food</td>\n",
       "      <td>positive</td>\n",
       "      <td>вкусно</td>\n",
       "      <td>Отмечали свадьбу 15 марта. Ах-Ах!!! Замечатель...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>538</td>\n",
       "      <td>1235</td>\n",
       "      <td>137</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       category sentiment    term  \\\n",
       "count      1367      1367    1367   \n",
       "unique        5         2     505   \n",
       "top        Food  positive  вкусно   \n",
       "freq        538      1235     137   \n",
       "\n",
       "                                                     text  \n",
       "count                                                1367  \n",
       "unique                                                371  \n",
       "top     Отмечали свадьбу 15 марта. Ах-Ах!!! Замечатель...  \n",
       "freq                                                   14  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>term</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">negative</th>\n",
       "      <th>count</th>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>105</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Food</td>\n",
       "      <td>дорого</td>\n",
       "      <td>Посещали это заведение 2 раза, ощущения разные...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>54</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">positive</th>\n",
       "      <th>count</th>\n",
       "      <td>1235</td>\n",
       "      <td>1235</td>\n",
       "      <td>1235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>402</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Food</td>\n",
       "      <td>вкусно</td>\n",
       "      <td>Отмечали свадьбу 15 марта. Ах-Ах!!! Замечатель...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>484</td>\n",
       "      <td>137</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 category    term  \\\n",
       "sentiment                           \n",
       "negative  count       132     132   \n",
       "          unique        5     105   \n",
       "          top        Food  дорого   \n",
       "          freq         54       5   \n",
       "positive  count      1235    1235   \n",
       "          unique        5     402   \n",
       "          top        Food  вкусно   \n",
       "          freq        484     137   \n",
       "\n",
       "                                                               text  \n",
       "sentiment                                                            \n",
       "negative  count                                                 132  \n",
       "          unique                                                 91  \n",
       "          top     Посещали это заведение 2 раза, ощущения разные...  \n",
       "          freq                                                    4  \n",
       "positive  count                                                1235  \n",
       "          unique                                                353  \n",
       "          top     Отмечали свадьбу 15 марта. Ах-Ах!!! Замечатель...  \n",
       "          freq                                                   14  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('sentiment').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Делаем датасет сбалансированным\n",
    "df = pd.concat([df[df['sentiment'] == 'positive'].sample(frac=1)[:150], df[df['sentiment'] == 'negative']]).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Загружаем модель\n",
    "m = 'web_0_300_20.bin'\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(m, binary=True)\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transit = {'ADJF':'ADJ',\n",
    "'ADJS' : 'ADJ',\n",
    "'ADVB' : 'ADV',\n",
    "'COMP' : 'ADV',\n",
    "'CONJ' : 'CCONJ',\n",
    "'GRND' : 'VERB',\n",
    "'INFN' : 'VERB',\n",
    "'INTJ' : 'INTJ',\n",
    "'LATN' : 'X',\n",
    "'NOUN' : 'NOUN',\n",
    "'NPRO' : 'PRON',\n",
    "'NUMB' : 'NUM',\n",
    "'NUMR' : 'NUM',\n",
    "'PNCT' : 'PUNCT' ,\n",
    "'PRCL' : 'PART',\n",
    "'PRED' : 'ADV',\n",
    "'PREP' : 'ADP',\n",
    "'PRTF' : 'ADJ',\n",
    "'PRTS' : 'VERB',\n",
    "'ROMN' : 'X',\n",
    "'SYMB' : 'SYM',\n",
    "'UNKN' : 'X',\n",
    "'VERB' : 'VERB'}\n",
    "\n",
    "robj = re.compile('|'.join(transit.keys()))\n",
    "\n",
    "def cleanization(text):\n",
    "    for line in text:\n",
    "        # 1. Все буквы в нижний регистр\n",
    "        text_text = text.lower()\n",
    "\n",
    "        # 2. Удаление всех небукв\n",
    "        letters_only = ''\n",
    "        for _c in text_text:\n",
    "            if _c in RUS_LETTERS:\n",
    "                letters_only += _c\n",
    "            else:\n",
    "                letters_only += ' '\n",
    "\n",
    "        # 3. Заменяем множественные пробелы\n",
    "        while '  ' in letters_only:\n",
    "            letters_only = letters_only.replace('  ', ' ')\n",
    "\n",
    "        # 4. Токенизация\n",
    "        word_list = tokenizer.tokenize(letters_only)\n",
    "\n",
    "        # 5. Лемматизация\n",
    "        clean_word_list = [morph.parse(word)[0].normal_form for word in word_list]  # лемматизация\n",
    "    \n",
    "        # 6. * Удаление стоп-слов + добавление тегов - части речи\n",
    "        # meaningful_words = [word for word in clean_word_list if word not in get_stop_words('ru')] # стоп-слова\n",
    "        meaningful_words = [str(word) + '_' + robj.sub(lambda m: transit[m.group(0)], str(morph.parse(word)[0].tag.POS)) for word in clean_word_list]\n",
    "        return ' '.join(meaningful_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'я_PRON сегодня_ADV съесть_VERB очень_ADV много_ADV мороженое_NOUN'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверка работы функции cleanization\n",
    "cleanization('Я сегодня съела очень много мороженого')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "def mean(a):\n",
    "    return sum(a) / len(a)\n",
    "\n",
    "\n",
    "def word2vec_mean(text):\n",
    "    \"\"\"Усредняет вектор слов.\"\"\"\n",
    "    arr = []\n",
    "    clean_text = cleanization(text)\n",
    "    # для каждого слова в тексте выводим его вектор\n",
    "    for word in clean_text.split(' '):\n",
    "        # есть ли слово в модели? Может быть, и нет\n",
    "        if word in model:\n",
    "            arr.append(model[word])\n",
    "    if len(list(map(mean, zip(*arr)))) != 0:\n",
    "        return list(map(mean, zip(*arr)))\n",
    "    else:\n",
    "        return [0 for i in range(0, 300)]\n",
    "\n",
    "\n",
    "\n",
    "class FunctionFeaturizer(TransformerMixin):\n",
    "    \"\"\" Для создания своего вектора я использовала усредненную векторизацию с помощью word2vec\"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        fvs = []\n",
    "        # fvs = word2vec_mean(X)  # если подавать по словам, а не датафрейм\n",
    "        for datum in X:\n",
    "            fv = word2vec_mean(datum)\n",
    "            fvs.append(fv)\n",
    "        return np.array(fvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7.33737042e-03,  -2.96452902e-02,   6.50390610e-02,\n",
       "          3.19109261e-02,   4.67816442e-02,  -6.75016195e-02,\n",
       "          1.34420572e-02,  -1.00418180e-01,   6.53345138e-02,\n",
       "          2.46328283e-02,  -7.88142625e-03,  -7.19515756e-02,\n",
       "         -3.37976255e-02,   2.32609529e-02,   5.84121747e-03,\n",
       "         -1.20705580e-02,  -3.55095118e-02,   5.70581928e-02,\n",
       "         -5.28854914e-02,   6.36451971e-03,   4.01164368e-02,\n",
       "         -4.82101887e-02,  -5.52522391e-02,   1.19763343e-02,\n",
       "          5.54701425e-02,  -1.48677127e-02,  -1.01240285e-01,\n",
       "          4.72908318e-02,   4.67002094e-02,   6.18545637e-02,\n",
       "         -1.20627820e-01,  -9.26931016e-03,   3.15161943e-02,\n",
       "          2.23013968e-03,  -3.23524722e-03,   3.60459499e-02,\n",
       "          2.32331306e-02,   4.34190817e-02,  -6.47412986e-02,\n",
       "          1.71083870e-04,   2.29924582e-02,  -2.39938311e-02,\n",
       "          3.65550630e-02,   5.90851046e-02,   4.88272235e-02,\n",
       "         -6.65662438e-02,   1.19906226e-02,   6.42403737e-02,\n",
       "         -5.50095029e-02,  -7.59308860e-02,   5.68110570e-02,\n",
       "          1.96577795e-02,   3.51579078e-02,   2.37929765e-02,\n",
       "          3.73131670e-02,  -8.25387146e-03,  -4.56062071e-02,\n",
       "          1.07027721e-02,   5.35744131e-02,   4.60452400e-02,\n",
       "         -1.07583538e-01,  -4.46126126e-02,  -1.11628845e-01,\n",
       "          1.55463954e-02,  -2.33858135e-02,  -1.63231026e-02,\n",
       "         -5.27138077e-02,  -3.21586095e-02,  -9.31867864e-03,\n",
       "         -6.00871183e-02,   7.69144297e-03,  -9.67709646e-02,\n",
       "         -3.65174375e-02,  -1.16793297e-01,   1.79343503e-02,\n",
       "          8.32767859e-02,  -8.87006149e-02,  -1.39374146e-02,\n",
       "          1.08059477e-02,   3.24390307e-02,   4.06219028e-02,\n",
       "         -3.57064046e-02,   4.15105745e-02,  -4.48481478e-02,\n",
       "         -8.47954070e-04,  -4.04333472e-02,   7.42429942e-02,\n",
       "         -3.70885395e-02,  -3.43977138e-02,  -1.01012178e-01,\n",
       "         -9.52832699e-02,   5.99603308e-03,   3.62775512e-02,\n",
       "          6.91484362e-02,  -4.79201265e-02,   2.69586071e-02,\n",
       "         -3.59099507e-02,   4.41464968e-02,   5.36971316e-02,\n",
       "         -6.23969026e-02,  -4.98496033e-02,  -2.95065157e-02,\n",
       "          5.80576025e-02,   1.33435766e-03,   5.38080595e-02,\n",
       "         -4.49722148e-02,  -1.61047261e-02,  -5.46122789e-02,\n",
       "          5.43172918e-02,   4.96269315e-02,   9.53349844e-02,\n",
       "         -1.00276871e-02,   4.93593328e-02,  -1.17983848e-01,\n",
       "          3.16709429e-02,  -6.36941344e-02,   4.82458957e-02,\n",
       "         -1.84206963e-02,   7.55869597e-02,   1.92815997e-02,\n",
       "         -8.05545822e-02,  -7.87510872e-02,   1.00902066e-01,\n",
       "         -7.52724335e-02,   6.67342916e-02,   6.79232227e-03,\n",
       "          6.14058180e-03,  -2.27839909e-02,   3.02080251e-02,\n",
       "         -8.91474541e-03,  -1.93737894e-02,  -6.65677572e-03,\n",
       "          1.22273285e-02,  -3.57017703e-02,   1.28744524e-02,\n",
       "          5.66195138e-02,   3.37915942e-02,   5.53175574e-03,\n",
       "         -2.14373618e-02,   2.16912273e-02,   8.63670260e-02,\n",
       "         -6.31804690e-02,  -7.11545274e-02,   1.57537833e-01,\n",
       "         -2.00965088e-02,   1.83915012e-02,   2.60768123e-02,\n",
       "         -7.18517751e-02,   1.33318588e-01,   1.14586435e-01,\n",
       "         -3.07227373e-02,   1.00430988e-01,   3.35246995e-02,\n",
       "          1.64553486e-02,  -1.36159640e-02,   1.03810906e-01,\n",
       "          6.37884662e-02,   7.19378889e-02,   2.98179220e-02,\n",
       "          5.66093810e-03,   7.73611665e-03,   5.69637083e-02,\n",
       "         -3.01328618e-02,  -1.20330462e-02,  -1.25127167e-01,\n",
       "         -6.01990595e-02,   5.54605313e-02,   1.95951946e-02,\n",
       "          8.70719701e-02,  -5.31316176e-02,  -1.37541503e-01,\n",
       "         -5.40807098e-02,   5.23522869e-02,   5.52811697e-02,\n",
       "          3.69942859e-02,   2.65072118e-02,   5.32024540e-02,\n",
       "         -8.83024037e-02,  -1.03159323e-01,  -8.04174989e-02,\n",
       "          7.91319311e-02,   1.19443219e-02,   2.55247261e-02,\n",
       "         -7.22669484e-03,  -2.70838812e-02,   1.13975734e-01,\n",
       "         -5.20299561e-02,  -1.92074757e-02,  -3.69469635e-02,\n",
       "         -4.83974320e-04,   1.59413554e-02,   2.50735190e-02,\n",
       "         -7.34729916e-02,   2.55540609e-02,  -4.04011756e-02,\n",
       "         -2.71206852e-02,  -6.28451854e-02,   2.54405066e-02,\n",
       "          2.47810110e-02,   5.14333919e-02,   8.77805352e-02,\n",
       "          3.03866677e-02,  -9.54938959e-03,   5.68374991e-02,\n",
       "         -1.00258039e-02,   8.02912749e-03,  -1.26202047e-01,\n",
       "          1.10016420e-01,  -6.39445335e-02,   6.53073341e-02,\n",
       "          3.67014222e-02,   1.33905470e-01,  -6.82632253e-02,\n",
       "          7.51117840e-02,   8.67511630e-02,   6.47527501e-02,\n",
       "         -7.32670128e-02,   3.95776592e-02,  -6.92951605e-02,\n",
       "         -1.63610675e-03,   6.26211464e-02,   2.48350743e-02,\n",
       "          8.60064756e-04,  -1.33936284e-02,  -9.38789919e-02,\n",
       "          9.31690112e-02,  -3.87312435e-02,   5.79011403e-02,\n",
       "         -4.18810807e-02,   3.69077399e-02,  -4.12086882e-02,\n",
       "         -2.40573417e-02,   3.67676243e-02,   2.51956973e-02,\n",
       "          4.15921919e-02,  -4.96886019e-03,   6.58675134e-02,\n",
       "         -1.13360556e-02,  -6.54481351e-02,   1.72580425e-02,\n",
       "         -4.44212034e-02,   1.37099206e-01,   1.68885421e-02,\n",
       "          3.59266698e-02,   1.07391529e-01,   2.73359157e-02,\n",
       "         -1.43210345e-03,   1.78239085e-02,  -6.93006888e-02,\n",
       "          3.60980211e-03,   4.44505550e-02,  -5.95020019e-02,\n",
       "          6.67023584e-02,  -4.10603285e-02,  -1.23165011e-01,\n",
       "         -7.89146638e-04,  -5.53632081e-02,  -2.12098937e-02,\n",
       "          1.29579427e-02,   7.21277744e-02,  -6.80514202e-02,\n",
       "         -4.39186208e-02,   8.36562961e-02,   2.05977987e-02,\n",
       "          2.53795572e-02,  -5.48061840e-02,  -3.96782458e-02,\n",
       "         -9.57643390e-02,  -7.18214959e-02,  -2.13964712e-02,\n",
       "         -8.59169941e-03,  -1.88672356e-02,  -5.68876527e-02,\n",
       "         -4.07934094e-05,  -7.28739947e-02,   4.41811346e-02,\n",
       "         -1.08724236e-01,  -4.53717411e-02,  -9.47109163e-02,\n",
       "         -6.72382936e-02,   1.07482271e-02,   2.06957068e-02,\n",
       "          5.33813089e-02,  -1.31671224e-02,  -6.33451808e-03,\n",
       "          3.75873297e-02,   4.53145653e-02,  -8.23803544e-02,\n",
       "          2.76018064e-02,  -1.79887097e-02,  -1.19373448e-01,\n",
       "          3.83833945e-02,  -8.69366229e-02,   1.08160630e-01,\n",
       "         -3.38304341e-02,  -6.92056045e-02,  -1.77072063e-02,\n",
       "          8.04798119e-03,   1.80761397e-01,  -7.48693664e-03],\n",
       "       [  6.79652439e-04,  -2.69875051e-02,   6.50019944e-02,\n",
       "          2.00012745e-02,   4.62110341e-03,  -4.19938723e-02,\n",
       "          5.88874756e-02,  -5.87675851e-02,   4.05330677e-02,\n",
       "         -3.12228007e-02,   1.86736970e-02,  -7.06777759e-02,\n",
       "         -2.30222959e-02,   4.20717215e-02,   1.96524595e-02,\n",
       "         -3.57177961e-02,  -2.15890887e-02,   5.89801315e-02,\n",
       "         -5.84770534e-02,   2.10402827e-02,   4.62298933e-02,\n",
       "         -7.78429247e-02,  -1.02232590e-01,   5.32764322e-02,\n",
       "          5.85735049e-02,  -3.52449161e-02,  -9.82636027e-02,\n",
       "         -4.90267389e-03,  -1.05191693e-02,  -4.38723713e-03,\n",
       "         -7.91791379e-02,  -3.71152005e-03,   6.38403632e-02,\n",
       "          1.29560624e-02,  -1.91179683e-02,   9.67286155e-03,\n",
       "          2.36896276e-02,   4.82440125e-02,  -3.14007672e-02,\n",
       "         -5.51152932e-03,   4.62970193e-02,  -4.44378834e-02,\n",
       "          3.08851581e-02,   5.57833686e-02,   4.41173837e-02,\n",
       "         -2.43290924e-02,   1.98057354e-02,   1.40138250e-02,\n",
       "          3.67232021e-02,  -8.00849758e-02,   3.56706865e-02,\n",
       "         -6.16654940e-03,   7.87442923e-03,  -3.48642794e-02,\n",
       "          4.44189515e-02,  -2.07115575e-02,  -3.03904498e-02,\n",
       "          8.34711036e-03,   1.72344893e-02,   2.11781394e-02,\n",
       "         -3.10704298e-02,  -3.35130636e-02,  -7.16953725e-02,\n",
       "         -3.52529110e-03,   1.37135899e-02,  -3.42069799e-02,\n",
       "         -5.39732054e-02,   2.05890089e-03,  -3.44435344e-02,\n",
       "         -9.50006191e-02,  -2.68304404e-02,  -1.04230903e-02,\n",
       "         -4.85343169e-02,  -7.36749796e-02,   2.80356025e-02,\n",
       "          5.40454192e-02,  -6.65954091e-02,  -2.43288116e-02,\n",
       "          3.95318028e-04,   7.22093843e-02,  -1.04106534e-02,\n",
       "         -5.99996801e-02,   2.87669487e-02,  -1.21029094e-03,\n",
       "          1.27876626e-02,  -3.67813986e-02,   8.83357376e-02,\n",
       "          6.09818473e-03,  -4.31706011e-02,  -4.12604548e-02,\n",
       "         -6.70304671e-02,  -2.67298776e-03,   8.85736197e-03,\n",
       "          4.02289317e-02,  -1.65437446e-02,   1.60517870e-02,\n",
       "         -5.57532310e-02,   1.55381211e-02,   6.28229007e-02,\n",
       "         -3.31168770e-02,  -5.05567845e-02,  -2.76411800e-02,\n",
       "          3.68228089e-02,  -4.52442190e-02,   4.32121512e-02,\n",
       "         -5.11777177e-02,   2.62184152e-02,  -5.53652905e-02,\n",
       "          7.91448969e-02,   4.96661011e-02,   1.40756082e-01,\n",
       "         -8.11149459e-03,  -4.23273016e-02,  -6.48664823e-02,\n",
       "          1.76870525e-02,  -5.50828557e-02,   3.58477030e-02,\n",
       "         -2.02027950e-02,   6.11263905e-02,  -3.99114005e-03,\n",
       "         -7.72709288e-02,  -3.96976625e-02,   3.47929001e-02,\n",
       "         -2.93746218e-03,   4.90665119e-02,   1.33746446e-02,\n",
       "          8.90057534e-04,  -1.03118736e-03,   2.39039771e-04,\n",
       "         -5.94413374e-03,  -1.11054715e-02,  -4.00450465e-02,\n",
       "         -1.08818980e-02,  -1.84082360e-02,  -1.66103197e-02,\n",
       "          4.50817868e-02,   4.33767475e-02,   6.41563635e-02,\n",
       "         -9.31084238e-03,   3.97276180e-02,   3.82284061e-02,\n",
       "         -1.05189320e-01,  -1.30368322e-02,   9.01293159e-02,\n",
       "         -2.81636203e-02,  -8.43344256e-03,   5.06107192e-02,\n",
       "         -8.60639364e-02,   9.26361736e-02,   4.90245372e-02,\n",
       "         -2.44124793e-03,   9.95554477e-02,   1.06472396e-02,\n",
       "         -7.87333027e-03,  -1.63792055e-02,   8.26882701e-02,\n",
       "          5.81443068e-02,   8.56573433e-02,   7.68323569e-02,\n",
       "          5.36216469e-02,  -2.40762625e-03,   8.66647381e-02,\n",
       "          1.91520220e-02,  -1.49047258e-02,  -1.07664224e-01,\n",
       "         -7.19131678e-02,   3.09594674e-02,   2.70101186e-02,\n",
       "          6.66536409e-02,  -2.41232389e-02,  -4.66007851e-02,\n",
       "         -7.06540346e-02,   3.03028552e-02,   4.94007692e-02,\n",
       "          7.63430744e-02,  -6.50667865e-03,  -4.79138829e-03,\n",
       "          6.73469156e-04,  -5.50460389e-02,  -1.11599542e-01,\n",
       "          3.57742114e-02,   2.08989680e-02,  -1.92516902e-02,\n",
       "          2.33596077e-02,   5.22629544e-03,   1.15122288e-01,\n",
       "         -3.86945829e-02,   2.79381210e-02,  -3.55212968e-02,\n",
       "         -4.41795436e-02,   1.93244470e-02,  -1.80007955e-02,\n",
       "         -4.20019976e-02,  -2.92163640e-02,  -3.53771448e-02,\n",
       "         -3.57047142e-02,   4.15952504e-03,  -1.04635004e-02,\n",
       "          2.98871715e-02,  -1.27194673e-02,   8.06708969e-02,\n",
       "         -1.64180864e-02,  -4.87599461e-02,   5.03277890e-02,\n",
       "         -3.23772491e-02,  -4.61332407e-03,  -8.07882026e-02,\n",
       "          5.56958144e-02,  -1.64882736e-02,   7.53549188e-02,\n",
       "         -2.28627641e-02,   1.51468761e-01,  -4.19369237e-02,\n",
       "          3.49201609e-02,   6.90703951e-02,   4.98840436e-02,\n",
       "         -6.14884011e-02,   5.84207904e-02,  -5.30501939e-02,\n",
       "          5.17077360e-03,   3.03897004e-02,   3.15342890e-02,\n",
       "         -3.09731888e-02,  -5.02392440e-02,  -5.00795753e-02,\n",
       "          7.82084130e-02,  -1.88177338e-02,   2.59902158e-02,\n",
       "         -5.16825058e-02,   2.73021944e-02,  -3.30457827e-02,\n",
       "         -5.89783303e-04,   6.04999401e-02,   2.58973846e-02,\n",
       "         -4.33521345e-04,  -4.76213028e-02,   4.39386228e-02,\n",
       "          1.74904238e-02,  -1.88251212e-02,  -5.52516989e-03,\n",
       "         -1.47913857e-02,   3.91091090e-02,  -2.81494670e-03,\n",
       "          5.87018616e-02,   2.87763402e-02,   2.37357505e-02,\n",
       "          3.69806017e-04,   4.80517168e-02,  -3.65362463e-02,\n",
       "         -1.56540668e-02,  -3.29148080e-02,  -7.42782895e-02,\n",
       "          3.47155696e-02,   2.52589174e-02,  -6.80364338e-02,\n",
       "         -1.73212456e-02,   1.04035735e-02,  -6.94417050e-02,\n",
       "          2.38599819e-02,   3.48898533e-02,  -3.32057584e-02,\n",
       "         -5.31168990e-02,   8.12205821e-02,   1.29857415e-02,\n",
       "          1.68297514e-02,  -6.16899189e-02,  -6.45232648e-02,\n",
       "         -8.45774375e-02,  -4.42215232e-02,   4.98112198e-03,\n",
       "         -1.23581174e-02,   1.21348463e-02,  -5.76664861e-02,\n",
       "         -5.49393564e-02,   6.29955158e-03,   3.60645354e-02,\n",
       "         -5.71779725e-02,   6.13463111e-03,  -6.06456390e-02,\n",
       "         -4.76287659e-02,   2.62512197e-02,   3.57758151e-02,\n",
       "          4.79579009e-02,  -2.75714351e-02,   1.42037752e-02,\n",
       "          2.48106197e-02,   1.37235802e-02,  -1.96699314e-02,\n",
       "          3.16643091e-02,  -3.06139095e-02,  -6.48813350e-02,\n",
       "          6.07022364e-03,  -1.58029944e-02,   9.93062891e-02,\n",
       "         -4.93248850e-02,  -2.42605051e-02,  -8.02482531e-03,\n",
       "         -8.86113197e-03,   8.02896060e-02,  -1.74022880e-02]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверка векторизатора\n",
    "df1 = pd.DataFrame({'text':['хороший', 'очень хороший'], 'class':['1', '0']})\n",
    "w2v_featurizer = FunctionFeaturizer() \n",
    "x = w2v_featurizer.transform(df1.text)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Делим корпус на тестовый и тернировочный\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['term'], df['sentiment'], test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258       претензионная\n",
       "430    профессиональное\n",
       "613              быстро\n",
       "522           не вкусно\n",
       "139    доброжелательный\n",
       "Name: term, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258    negative\n",
       "430    positive\n",
       "613    positive\n",
       "522    negative\n",
       "139    positive\n",
       "Name: sentiment, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count        253\n",
       "unique       180\n",
       "top       вкусно\n",
       "freq          14\n",
       "Name: term, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_smth_with_model(data_train, class_train, data_test, class_test, steps):\n",
    "    print('\\nModel train')\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "\n",
    "    cv_results = cross_val_score(pipeline,\n",
    "                                 data_train,\n",
    "                                 class_train,\n",
    "                                 cv=10,\n",
    "                                 scoring='accuracy',\n",
    "                                )\n",
    "    print(cv_results.mean(), cv_results.std())\n",
    "\n",
    "    pipeline.fit(data_train, class_train)\n",
    "    class_predicted = pipeline.predict(data_test)\n",
    "    print(class_predicted)\n",
    "\n",
    "    print(classification_report(class_test, class_predicted ))\n",
    "\n",
    "    return pipeline, class_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w2v_featurizer = FunctionFeaturizer()  # создание своего векторизатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Custom Transformer\n",
      "\n",
      "Model train\n",
      "0.878076923077 0.0523608327353\n",
      "['negative' 'negative' 'positive' 'negative' 'negative' 'positive'\n",
      " 'negative' 'negative' 'negative' 'negative' 'positive' 'negative'\n",
      " 'positive' 'positive' 'positive' 'negative' 'negative' 'negative'\n",
      " 'positive' 'negative' 'positive' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'positive' 'positive' 'negative']\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.74      1.00      0.85        14\n",
      "   positive       1.00      0.67      0.80        15\n",
      "\n",
      "avg / total       0.87      0.83      0.82        29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Свой векторизатор\n",
    "print('\\nCustom Transformer')\n",
    "lr_pipeline, label_predicted = do_smth_with_model(X_train, y_train,\n",
    "                                               X_test, y_test, \n",
    "                                               steps=[('custom', w2v_featurizer),\n",
    "                                                      ('classifier', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Custom Transformer\n",
      "\n",
      "Model train\n",
      "0.847 0.0591039879688\n",
      "['positive' 'negative' 'positive' 'negative' 'negative' 'positive'\n",
      " 'negative' 'positive' 'positive' 'negative' 'positive' 'negative'\n",
      " 'positive' 'negative' 'positive' 'negative' 'negative' 'negative'\n",
      " 'positive' 'positive' 'positive' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'positive' 'positive' 'negative']\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.88      1.00      0.93        14\n",
      "   positive       1.00      0.87      0.93        15\n",
      "\n",
      "avg / total       0.94      0.93      0.93        29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Свой векторизатор\n",
    "print('\\nCustom Transformer')\n",
    "etx_pipeline, label_predicted = do_smth_with_model(X_train, y_train,\n",
    "                                               X_test, y_test, \n",
    "                                               steps=[('custom', w2v_featurizer),\n",
    "                                                      ('classifier', ExtraTreesClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Custom Transformer + RandomForestClassifier\n",
      "\n",
      "Model train\n",
      "0.843461538462 0.0731885786673\n",
      "['negative' 'positive' 'positive' 'negative' 'negative' 'positive'\n",
      " 'negative' 'positive' 'negative' 'negative' 'positive' 'negative'\n",
      " 'positive' 'positive' 'positive' 'negative' 'negative' 'negative'\n",
      " 'positive' 'positive' 'positive' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'positive' 'positive' 'negative']\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.81      0.93      0.87        14\n",
      "   positive       0.92      0.80      0.86        15\n",
      "\n",
      "avg / total       0.87      0.86      0.86        29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Word2Vec + RandomForestClassifier\n",
    "print('\\nCustom Transformer + RandomForestClassifier')\n",
    "rf_pipeline, label_predicted = do_smth_with_model(X_train, y_train,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   X_test, y_test,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   steps=[('custom', w2v_featurizer),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t  ('classifier', RandomForestClassifier())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Custom Transformer + DecisionTreeClassifier\n",
      "\n",
      "Model train\n",
      "0.842858974359 0.0635821968744\n",
      "['positive' 'negative' 'positive' 'negative' 'positive' 'positive'\n",
      " 'negative' 'positive' 'positive' 'negative' 'positive' 'negative'\n",
      " 'positive' 'positive' 'positive' 'negative' 'positive' 'negative'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'negative'\n",
      " 'negative' 'negative' 'positive' 'positive' 'negative']\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       1.00      0.79      0.88        14\n",
      "   positive       0.83      1.00      0.91        15\n",
      "\n",
      "avg / total       0.91      0.90      0.90        29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Word2Vec + DecisionTreeClassifier\n",
    "print('\\nCustom Transformer + DecisionTreeClassifier')\n",
    "dt_pipeline, label_predicted = do_smth_with_model(X_train, y_train,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   X_test, y_test,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   steps=[('custom', w2v_featurizer),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t  ('classifier', DecisionTreeClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка работы модели на наших тестовых коллокациях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'text':['отличный выбор', 'не советуем', 'очень советуем', 'очень дорого', 'выше всяких похвал', 'в общем прекрасно', 'нам все понравилось']})\n",
    "# , 'в целом ничего', 'отвратительный', 'быстро', 'очень плохое обслуживание', 'отличное меню', 'хороший', 'вкусный', 'замечательный', 'приятный', 'красивый', 'отличный'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>отличный выбор</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>не советуем</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>очень советуем</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>очень дорого</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>выше всяких похвал</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 text\n",
       "0      отличный выбор\n",
       "1         не советуем\n",
       "2      очень советуем\n",
       "3        очень дорого\n",
       "4  выше всяких похвал"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = w2v_featurizer.transform(df1.text)  # векторизуем наши слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02267521, -0.02004785, -0.0533559 , ..., -0.00224797,\n",
       "         0.07374597, -0.04249991],\n",
       "       [-0.01177259, -0.06730742,  0.06288135, ..., -0.01996527,\n",
       "         0.11107853, -0.05057059],\n",
       "       [-0.00887533, -0.04581857,  0.06392314, ..., -0.02286776,\n",
       "         0.04544817, -0.03894411],\n",
       "       ..., \n",
       "       [ 0.01659136, -0.02731018, -0.00448782, ...,  0.04818018,\n",
       "         0.00575948, -0.09879748],\n",
       "       [ 0.04194519, -0.08253068, -0.0113095 , ..., -0.06132992,\n",
       "         0.02059018, -0.05131358],\n",
       "       [-0.03626946,  0.05354116,  0.04102799, ..., -0.03269978,\n",
       "         0.08353947, -0.05340419]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.878076923077 0.0523608327353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['positive', 'negative', 'negative', 'negative', 'negative',\n",
       "       'negative', 'positive'], dtype=object)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(w2v_featurizer.transform(X_train), y_train)\n",
    "cv_results = cross_val_score(lr_model, w2v_featurizer.transform(X_train), y_train, cv=10, scoring='accuracy')\n",
    "print(cv_results.mean(), cv_results.std())\n",
    "lr_model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "отвратительный : negative\n",
      "быстро : positive\n",
      "очень плохое обслуживание : negative\n",
      "отличное меню : negative\n"
     ]
    }
   ],
   "source": [
    "# Проверка работы модели на наших тестовых коллокациях\n",
    "def predictor(collocations_array, pipeline):\n",
    "    arr = []\n",
    "    df1 = pd.DataFrame({'text': collocations_array})\n",
    "    for i in df1.text:\n",
    "        arr.append(i)\n",
    "    с = 0\n",
    "    for i in pipeline.predict(df1.text):\n",
    "        print(arr[с], ':', i)\n",
    "        с += 1\n",
    "\n",
    "\n",
    "collocations_array = ['отвратительный', 'быстро', 'очень плохое обслуживание', 'отличное меню']\n",
    "predictor(collocations_array, etx_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "отличный выбор : negative\n",
      "не советуем : negative\n",
      "очень советуем : negative\n",
      "очень дорого : negative\n",
      "выше всяких похвал : negative\n",
      "в общем прекрасно : negative\n",
      "нам все понравилось : negative\n",
      "в целом ничего : negative\n",
      "отвратительный : negative\n",
      "быстро : positive\n",
      "очень плохое обслуживание : negative\n",
      "отличное меню : negative\n",
      "хороший : positive\n",
      "вкусный : positive\n",
      "замечательный : positive\n",
      "приятный : positive\n",
      "красивый : positive\n",
      "отличный : negative\n",
      "8\n",
      "______________________________\n",
      "отличный выбор : positive\n",
      "не советуем : negative\n",
      "очень советуем : negative\n",
      "очень дорого : negative\n",
      "выше всяких похвал : negative\n",
      "в общем прекрасно : negative\n",
      "нам все понравилось : positive\n",
      "в целом ничего : negative\n",
      "отвратительный : negative\n",
      "быстро : positive\n",
      "очень плохое обслуживание : negative\n",
      "отличное меню : positive\n",
      "хороший : positive\n",
      "вкусный : positive\n",
      "замечательный : positive\n",
      "приятный : positive\n",
      "красивый : positive\n",
      "отличный : positive\n",
      "4\n",
      "______________________________\n",
      "отличный выбор : positive\n",
      "не советуем : negative\n",
      "очень советуем : negative\n",
      "очень дорого : negative\n",
      "выше всяких похвал : negative\n",
      "в общем прекрасно : positive\n",
      "нам все понравилось : negative\n",
      "в целом ничего : positive\n",
      "отвратительный : negative\n",
      "быстро : positive\n",
      "очень плохое обслуживание : negative\n",
      "отличное меню : positive\n",
      "хороший : positive\n",
      "вкусный : positive\n",
      "замечательный : positive\n",
      "приятный : positive\n",
      "красивый : positive\n",
      "отличный : positive\n",
      "3\n",
      "______________________________\n",
      "отличный выбор : positive\n",
      "не советуем : negative\n",
      "очень советуем : negative\n",
      "очень дорого : negative\n",
      "выше всяких похвал : positive\n",
      "в общем прекрасно : negative\n",
      "нам все понравилось : negative\n",
      "в целом ничего : negative\n",
      "отвратительный : negative\n",
      "быстро : positive\n",
      "очень плохое обслуживание : negative\n",
      "отличное меню : positive\n",
      "хороший : positive\n",
      "вкусный : positive\n",
      "замечательный : negative\n",
      "приятный : positive\n",
      "красивый : positive\n",
      "отличный : positive\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "collocations_array = ['отличный выбор', 'не советуем', 'очень советуем', 'очень дорого', 'выше всяких похвал', 'в общем прекрасно', 'нам все понравилось', 'в целом ничего', 'отвратительный', 'быстро', 'очень плохое обслуживание', 'отличное меню', 'хороший', 'вкусный', 'замечательный', 'приятный', 'красивый', 'отличный']\n",
    "\n",
    "\n",
    "# Ввести правильные ответы\n",
    "true = {'отличный выбор': 'positive',\n",
    "'не советуем': 'negative',\n",
    "'очень советуем': 'positive',\n",
    "'очень дорого': 'negative',\n",
    "'выше всяких похвал': 'positive',\n",
    "'в общем прекрасно': 'positive',\n",
    "'нам все понравилось': 'positive',\n",
    "'в целом ничего': 'positive',\n",
    "'отвратительный': 'negative',\n",
    "'быстро': 'positive',\n",
    "'очень плохое обслуживание': 'negative',\n",
    "'отличное меню' : 'positive',\n",
    "'хороший' : 'positive',\n",
    "'вкусный' : 'positive',\n",
    "'замечательный' : 'positive',\n",
    "'приятный' : 'positive',\n",
    "'красивый' : 'positive',\n",
    "'отличный' : 'positive'}\n",
    "\n",
    "\n",
    "\n",
    "# Проверка работы модели на наших тестовых коллокациях\n",
    "def predictor(collocations_array, pipeline):\n",
    "\tmistakes = 0\n",
    "\tarr = []\n",
    "\tdf1 = pd.DataFrame({'text': collocations_array})\n",
    "\tfor i in df1.text:\n",
    "\t\tarr.append(i)\n",
    "\tс = 0\n",
    "\tfor i in pipeline.predict(df1.text):\n",
    "\t\tprint(arr[с], ':', i)\n",
    "\t\tif true[arr[с]] != i:\n",
    "\t\t\tmistakes += 1\n",
    "\t\tс += 1\n",
    "\tprint(mistakes)\n",
    "\n",
    "\n",
    "# ВВЕДИТЕ СЛОВА, КОТОРЫЕ ХОТИТЕ ПРОВЕРИТЬ\n",
    "predictor(collocations_array, etx_pipeline)\n",
    "print('_'*30)\n",
    "predictor(collocations_array, lr_pipeline)\n",
    "print('_'*30)\n",
    "predictor(collocations_array, rf_pipeline)\n",
    "print('_'*30)\n",
    "predictor(collocations_array, dt_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
